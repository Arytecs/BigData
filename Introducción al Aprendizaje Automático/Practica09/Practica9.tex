\documentclass[12pt,twoside]{article}

% La extensión total de la memoria deberá ser de un máximo de 50 páginas (excluidos resumen, índice y posibles anexos).

% Según las recomendaciones de estilo, el formato de la memoria se ajustará a lo siguiente:
% ? Formato del papel: DIN A4.
% ? Impresión a dos caras.
% ? Márgenes: superior e inferior, 2.5 cm. Márgenes laterales: páginas impares, izquierdo 4 cm y derecho 2 cm; páginas % pares, izquierdo 2 cm y derecho 4 cm.
% ? Tipo de letra: Times New Roman de 12 puntos.
% ? Interlineado: 1.5 líneas.
% ? Alineación: justificación completa.
% ? Sangrado de párrafo: 0.5 cm la primera línea de cada párrafo. No se
%pondrá espacio entre párrafos.
% ? Las páginas deberán ir numeradas en números arábigos.

% Teniendo en cuenta las indicaciones previas, definimos el estilo en LaTeX:

% Indicaciones para el idioma:
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[spanish]{babel}
\usepackage{float}

% Adaptación de itemize y enumerate a los usos tipograficos españoles:
\let\layoutspanish\relax
\addto\captionsspanish{\def\tablename{Tabla}} % para que escriba "Tabla" en lugar de "Cuadro"
\unaccentedoperators  % para que no acentúe los operadores

% Área de impresión de una página:
\usepackage[a4paper]{geometry}
  \geometry{hmargin={2.5cm,2.5cm},height=22cm}

% Formato de algunas distancias:
\renewcommand{\baselinestretch}{1.2}    % separación entre líneas de un mismo párrafo
\setlength{\partopsep}{0pt}
\setlength{\itemsep}{0pt}
\setlength{\topsep}{0pt}
\setlength{\parsep}{0pt}
\setlength{\parskip}{0.25\baselineskip}   % separación entre párrafos

\renewcommand{\textfraction}{0.1}   % mínima fracción de la página para el texto
\renewcommand{\topfraction}{1}      % máxima fracción de la página para objetos flotantes en la parte superior
\renewcommand{\bottomfraction}{1}
\renewcommand{\floatpagefraction}{1}

\setcounter{totalnumber}{5}
\setcounter{topnumber}{3}
\setcounter{bottomnumber}{2}

% Adaptación de las "caption" de los entorns "figure" y "table":
\usepackage{caption}
\setcaptionwidth{\textwidth}
\addtolength{\captionwidth}{-2\parindent}
\captionsetup{margin=\leftmargini,%
  width=\captionwidth,%
  labelfont={up,bf},%
  font={small,sl},%
  %indention={\captionindent
}

% Indentación del primer párrafo de una sección:
\usepackage{indentfirst}

% Definición del color grisclaro en la salida PDF:
\usepackage[pdftex]{color}

% Gráficos:
\usepackage[pdftex]{graphicx}

% Paquetes recomendados para la inclusión de fórmulas matemáticas:
\usepackage{amsmath}
\allowdisplaybreaks  % para que pueda partir fórmulas que ocupan más de una línea, necesita el paquete anterior
\usepackage{amssymb} % para cargar algunos símbolos como \blacksquare y \square
\usepackage{amsfonts} % para cargar algunas fuentes en estilo matemático
\usepackage{enumerate}
\usepackage{listings}

% Teoremas (se pueden definir todos los que se necesiten):

\newtheorem{theorem}{Teorema}[section]
\newtheorem{proposition}[theorem]{Proposición}
\newtheorem{definition}[theorem]{Definición}
\newtheorem{lemma}[theorem]{Lema}
\newtheorem{corollary}[theorem]{Corolario}
\newtheorem{example}[theorem]{Ejemplo}
\newtheorem{app}[theorem]{Aplicación}
\newtheorem{remark}[theorem]{Observación}
\newtheorem{agrad}[theorem]{Agradecimiento}
\newtheorem{algo}[theorem]{Algoritmo}
\newtheorem{axiom}[theorem]{Axioma}
\newtheorem{case}[theorem]{Caso}
\newtheorem{conclu}[theorem]{Conclusión}
\newtheorem{conjectura}[theorem]{Conjetura}
\newtheorem{notac}[theorem]{Notación}
\newtheorem{soluc}[theorem]{Solución}
\newtheorem{summary}[theorem]{Sumario}


\newtheorem{proof}[theorem]{Demostración.}
\renewenvironment{proof}{\emph{Demostración.}} {\quad \hfill $\blacksquare$ \newline} % para que aparezca un cuadrado negro al acabar la demostración


% Definición de cabeceras y pies de página:

\usepackage{fancyhdr}                     % para definir distintos tipos de cabeceras y pies de página

\newcommand{\RunningAuthor}{Jose Joaquín Rodríguez García y Araceli Teruel Domenech}
\newcommand{\Author}[1]{\renewcommand{\RunningAuthor}{#1}}
\renewcommand{\leftmark}{\RunningAuthor}

\newcommand{\RunningTitle}{Práctica 3 Introducción al Aprendizaje Automático}
\newcommand{\Title}[1]{\renewcommand{\RunningTitle}{#1}}
\renewcommand{\rightmark}{\RunningTitle}

\pagestyle{fancy}
\fancyhf{}
\fancyhead[LO]{\small \slshape \leftmark}    % lo que aparece en la parte izquierda de la páginas impares
\fancyhead[RE]{\small \slshape \rightmark}   % lo que aparece en la parte derecha de las páginas pares
\fancyhead[RO,LE]{\small \slshape \thepage}  % el número de página aparece en la parte exterior de la cabecera

\renewcommand{\headrulewidth}{0.6pt}         % grueso de la línea horizontal por debajo de la cabecera de la página
\renewcommand{\footrulewidth}{0pt}           % grueso de la línea horizontal por encima del pie de página
                                             % en este caso está vacío
\setlength{\headheight}{1.5\headheight}      % aumenta la altura de la cabecera en una parte y media

\fancypagestyle{plain}{%                     % redefinición del estilo de página 'plain'
  \fancyhf{}                                 % limpia todas las cabeceras y pies de página
  \setlength{\headwidth}{\textwidth}
  \fancyfoot[C]{\small \slshape \thepage}    % excepto el centro del pie de página
  \renewcommand{\headrulewidth}{0pt}
  \renewcommand{\footrulewidth}{0pt}
  }

% Instrucciones que se usan frecuentemente
\newcommand{\abs}[1]{\ensuremath{|#1|}}

% Datos del trabajo y autor:
\title{Práctica 9 Introducción al Aprendizaje Automático}
\author{Jose Joaquín Rodríguez García y Araceli Teruel Domenech\\*[1em]
\begin{minipage}{0.75\textwidth}
\footnotesize \itshape
\begin{center}
Universidad Politécnica de Valencia \\
Master en Big Data Analytics
\end{center}
\end{minipage}
}
\date{Octubre 2017}

% Para incluir paginas de otro pdf (por ejemplo, la de la portada):
\usepackage{pdfpages}
\usepackage{graphicx}
\graphicspath{ {images/} }


\begin{document}

\maketitle


\section{Primera Tarea}

\subsection{Enunciado}

\noindent
Repasad el códgio del siguiente programay ejecutadlo repetidas veces para ver la capacidad de las redes neuronales como clasificadores.
\begin{center}
\textsf{test-ann.py}
\end{center}

Este programa Python hace uso de la implmentación de las redes facilitada en la carpeta \textit{ann}. El estudio del código de las redes neuronales es opcional y se recomienda que cada persona lo realice por su cuenta si dispone de tiempo. Tener que implementar las redes excede los objetivos del presente curso.

Sí que se pide en esta tarea que los alumnos prueben diferentes topologías de la red y diferentes tipos de función de activación en cada una de las capas. Los tipos de activación disponibles son: \textbf{linear}, \textbf{llinear rectified}, \textbf{lbinary}, \textbf{lsigmoid}, \textbf{ltanh} y \textbf{lsoftmas}.

Se recomienda utilizr softmax y linear únicamente en la capa de salida. El primero para clasificación y el segundo para regresión.
Para el ejemplo de esta tarea, el problema XOR, se recomienda poner a verdadero la variable
\begin{center}
\textsf{xor\_example = True}
\textsf{plot\_examples = True}
\end{center}
para que se representen las muestras del training set por pantalla, al menos para una ejecución. De esta manera uno se puede hacer una idea del problema.

Deben probarse distintos tamaños para la capa interna, de 2 a 512 neuronas, se pueden probar las potencias de 2, por ejemplo, y ver qué efecto tiene el número de neuronas ocultas. Las capas de entrada y salida tienen fijado el tamaño, la de entrada según la dimensionalidad de las muestras. La de salida según el número de clases a distinguir.

Deben probarse distintas funciones de activación para la capa oculta, todas salvo \textbf{linear} y \textbf{softmax}, y dado que es un problema de clasificación, para la salida pueden probarse las siguientes: \textbf{linear}, \textbf{softmax}, \textbf{tanh} y \textbf{sigmoid}.

Se recomienda repasar el código de la función \textbf{to\_one\_hot()} para ver cómo preparar un vector de salida para la red según la clase a la que pertenezca la muestra utilizada para entrenamiento en ese instante.

Como última prueba sobre el problema del XOR, las muestras se han separado mediante con un margen entre cada cuadrante.
\begin{center}
\textsf{margin=1.0}
\end{center}
Cambiad el valor del margen a 0 para que las muestras estén juntas, apenas separadas por los ejes de coordenadas, y observad cómo se comportan las redes neuronales y cómo se comporta un clasificador del tipo KDE que se ha estado utilizando como referencia. ¿A qué tipo de clasificador afecta más el hecho de que las muestras no estén separadas por cierto margen?

¿Qué topología de la red y qué funciones de activación se adaptan mejor a cada caso?
Variad el número de muestras, por ejemplo \textbf{n\_samples} igual a {50,100,200,500,1000,2000}

¿Qué efecto tiene el número de muestras con respecto a las redes neuronales ya al clasificador KDE cuando las muestras no están separadas vía un margen?



\subsection{Resolución}


\section{Segunda Tarea}

\subsection{Enunciado}
Seguid trabajando con el mismo programa, pero en este caso poned a falso la variable \textsf{xor\_example} para que automáticamente se ejecute el código correspondiente a la generación de muestras siguiendo distribuciones normales o de Gauss.

Comprobad el efecto de los cambios propuestos en la tarea anterior para este caso.

Dado que las muestras se general siempre de manera aleatoria, que sirva la precisión obtenida con el clasificador de tipo KDE como referente para ver qué configuraciones de las redes van bien y cuando no es necesario aumentar en número de neuronas de la capa oculta.


\subsection{Resolución}

\section{Tercera Tarea}

\subsection{Enunciado}
A partir del código anterior más el código utilizado en prácticas anteriores, aplicad las redes neuronales sobre el dataset MNIST.

Por el tamaño del dataset y por la alta dimensionalidad de las muestras el entrenamiento no será lento. Aunque debe probarse sin transformaciones lanzando un proceso que tardará bastante (esto debe de hacerse fuera del laboratorio), se propone, qpara poder probar en el laboratorio, reducir la dimensionalidad mediante PCA y utilizar un conjunto de muestras reducido para la fase de aprendizaje, por ejemplo 1000 y también probad con 2000-

Probad distintas configuraciones de la red para ver cual es la más adecuada a este problema.

\subsection{Resolución}

\section{Cuarta Tarea}
\subsection{Enunciado}
Se trata del dataset utilizado en la tarea 3 de la práctica sobre SVM. Esta tarea consiste en aplicar las redes neuronales sobre el mencionado dataset realizando las mismas pruebas de configuraciones de las redes como se ha hecho en las tareas anteriores. Partid del código disponible en la Web de Scikit Learn y que se utilizó en la anterior práctica.

\subsection{Resolución}

\end{document} 